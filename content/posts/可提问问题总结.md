---
title: "可提问问题总结"
date: 2019-10-27T19:10:30+08:00
draft: false
toc: true
comments: true
tags:
  - untagged
---

## SQL/数仓类

### 如何统计互粉数量

存在一张关注表relation，有两个字段：

* 关注者id（from_user_id bigint）
* 被关注者id（to_user_id bigint）

计算存在多少对互粉的用户

### 如何验证数据前后一致性

在对一张表的产出逻辑进行优化或者更该时如何校验修改后的产出和之前的逻辑一致（也就是说，校验前后产出数据一致）

### 如何实现增量merge

现在在hive中有一张全量mysql dump表，每天会通过binlog得到mysql每天的增量dump表，在指定主键的情况下，如何通过SQL产出全量表。字段如下：

all_dump

* date 分区字段
* id 主键
* data 数据

delta_dump

* date 分区字段
* id 主键
* data 数据
* type 枚举值 （insert、update、delete）

### 历史累计表如何实现的两种方式

daily表

* date 分区
* id 主键
* vv 指标（可加）

history

* date 分区
* id 主键
* vv 指标（可加）

### Spark shuffle相关

```sql
select
  t1.a, t1.b,
  count(1) as uv,
  sum(vv) as vv
from
(
  select
    t1.a, t1.b, t1.c,
    count(1) as vv
  from t1
  left join t2
  on t1.a = t2.a
  group by t1.a, t1.b, t1.c
) x
group by t1.a, t1.b
```

上面SQL有几个shuffle，为什么？

[spark笔记](/posts/spark-笔记/#4-前缀优化)

## 算法

### 模糊搜索简单实现

常见的带搜索的下拉框，匹配方式一般都是通过子串匹配实现的。但是不够方便，现在希望实现模糊匹配，例如

* 用户输入：lu
* 匹配项：
    * `log.user_id` -> true
    * `xxxlxxxuxx` -> true
    * `luxxx` -> true
    * `lxxxx` -> false

### 实现未来最近的一个星期x距离今天有几天

```scala
/**
 * @param x 要查找的最近的一个星期x
 * @param todayOfWeek 今天是周几
 * @return 未来最近的一个星期x距离今天有几天
 */
def solve(x: Int, todayOfWeek: Int): Int;
```

### 亿级别ID压缩查找

文件中有1亿个不重复long（64位），大部分数值比较小。

要求内存占用尽量小，查询效率logn，不会更新插入。

方案：

* 读入并排序
* varint 压缩，并记录长度字节
* 二分查找

### Hive SQL 文件 按照分号Split

## 工程

### 分布式id下发

在实现一个分布式无状态服务时，需要给每个节点分配一个独一无二的id，且满足：

* id的范围为 [0, 31]
* 每个实例都可以是id范围内的任意一个，但是不能重复
* 集群随时可能扩缩容

### 如何实现cron调度系统

要求

* 高可用
* only one
* 灵活扩缩容
